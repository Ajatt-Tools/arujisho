{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "skilled-journalism",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:24:21.757181Z",
     "start_time": "2022-09-23T00:24:21.745632Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pykakasi\n",
    "import re\n",
    "import bisect\n",
    "import sqlite3\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d187e41f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:24:22.476931Z",
     "start_time": "2022-09-23T00:24:22.190681Z"
    }
   },
   "outputs": [],
   "source": [
    "katakana = ''.join(map(chr, range(0x30a1, 0x30fb))) + 'ー' + '々'\n",
    "hiragana = ''.join(map(chr, range(0x3041, 0x3097)))\n",
    "cjkranges = [\n",
    "    # compatibility ideographs\n",
    "    {\"from\": ord(u\"\\u3300\"), \"to\": ord(u\"\\u33ff\")},\n",
    "    # compatibility ideographs\n",
    "    {\"from\": ord(u\"\\ufe30\"), \"to\": ord(u\"\\ufe4f\")},\n",
    "    # compatibility ideographs\n",
    "    {\"from\": ord(u\"\\uf900\"), \"to\": ord(u\"\\ufaff\")},\n",
    "    # compatibility ideographs\n",
    "    {\"from\": ord(u\"\\U0002F800\"), \"to\": ord(u\"\\U0002fa1f\")},\n",
    "    # cjk radicals supplement\n",
    "    {\"from\": ord(u\"\\u2e80\"), \"to\": ord(u\"\\u2eff\")},\n",
    "    {\"from\": ord(u\"\\u3400\"), \"to\": ord(u\"\\u9fff\")},\n",
    "    {\"from\": ord(u\"\\U00020000\"), \"to\": ord(u\"\\U0002a6df\")},\n",
    "    {\"from\": ord(u\"\\U0002a700\"), \"to\": ord(u\"\\U0002b73f\")},\n",
    "    {\"from\": ord(u\"\\U0002b740\"), \"to\": ord(u\"\\U0002b81f\")},\n",
    "    {\"from\": ord(u\"\\U0002b820\"), \"to\": ord(u\"\\U0002ceaf\")},\n",
    "    {\"from\": ord(u\"\\U0002ceb0\"), \"to\": ord(u\"\\U0002ebef\")},\n",
    "    {\"from\": ord(u\"\\U0002f800\"), \"to\": ord(u\"\\U0002fa1f\")},\n",
    "    {\"from\": ord(u\"\\U00030000\"), \"to\": ord(u\"\\U0003134f\")},\n",
    "]\n",
    "\n",
    "\n",
    "def is_cjk(char):\n",
    "    return any([range[\"from\"] <= ord(char) <= range[\"to\"] for range in cjkranges])\n",
    "\n",
    "\n",
    "latin = range(0x41, 0x17f)\n",
    "kks = pykakasi.kakasi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b62bba59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:25:03.636284Z",
     "start_time": "2022-09-23T00:24:22.746685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq, BCCWJ-LUW, 4\n",
      "Freq, CC100, 4\n",
      "Freq, Innocent Ranked, 0.01\n",
      "Freq, JPDB, 0.2\n",
      "Freq, Netflix, 0.2\n",
      "Freq, Novels, 0.1\n",
      "Freq, TWC, 0.6\n",
      "Freq, Wikipedia, 1\n",
      "Freq, 国語辞典, 0.8\n"
     ]
    }
   ],
   "source": [
    "use_cache = False\n",
    "if os.path.exists('words.pkl'):\n",
    "    words = pickle.load(open('words.pkl', 'rb'))\n",
    "    use_cache = True\n",
    "\n",
    "freqs = {}\n",
    "for dir in os.listdir('jisho'):\n",
    "    if 'Freq' in dir:\n",
    "        index = json.load(open('jisho/'+dir+'/index.json', 'r'))\n",
    "        for j in filter(lambda x: 'term_meta_bank' in x, os.listdir('jisho/'+dir)):\n",
    "            for term in json.load(open('jisho/'+dir+'/'+j, 'r')):\n",
    "                weight = 1 if 'weight' not in index else index['weight']\n",
    "                word, _, freq = term\n",
    "                assert _ == 'freq'\n",
    "                wk = word\n",
    "                if type(freq) is dict and 'reading' in freq:\n",
    "                    yomikata = freq['reading']\n",
    "                    if not all(map(lambda x: x in hiragana, yomikata)):\n",
    "                        yomikata = ''.join(\n",
    "                            map(lambda x: x['hira'], kks.convert(yomikata)))\n",
    "                    wk = (word, yomikata)\n",
    "                    weight *= 3\n",
    "                    freq = freq['frequency']\n",
    "                elif all(map(lambda x: x in hiragana or x in katakana, word)):\n",
    "                    weight *= 1.8\n",
    "                if type(freq) is dict and 'value' in freq:\n",
    "                    if not all(map(lambda x: x in hiragana or x in katakana, word)):\n",
    "                        if \"㋕\" in freq['displayValue']:\n",
    "                            weight *= 0.5\n",
    "                    freq = freq['value']\n",
    "                if use_cache:\n",
    "                    if type(wk) is str and (not all(map(lambda x: x in hiragana or x in katakana, wk))) and wk in words and len(words[wk]) == 1:\n",
    "                        wk = (wk, words[wk][0][1])\n",
    "                        weight *= 3\n",
    "                if wk not in freqs:\n",
    "                    freqs[wk] = 0\n",
    "                freqs[wk] += 2**(12 - freq**0.5/30)*weight\n",
    "        print(\n",
    "            f\"Freq, {index['title']}, {1 if 'weight' not in index else index['weight']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d0d321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:25:03.645096Z",
     "start_time": "2022-09-23T00:25:03.638556Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_struct(x):\n",
    "    if type(x) is str:\n",
    "        yield x\n",
    "    elif x['tag'] == 'img':\n",
    "        pass\n",
    "    elif x['tag'] == 'div':\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "        yield '\\n'\n",
    "    elif x['tag'] == 'span':\n",
    "        yield '('\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "        yield ')'\n",
    "    elif x['tag'] == 'a':\n",
    "        assert type(x['content']) is str\n",
    "        yield f\"【{x['content']}】\"\n",
    "    elif x['tag'] == 'br':\n",
    "        yield '\\n'\n",
    "    elif x['tag'] == 'ruby':\n",
    "        yield f\"({x['content'][0]})\"\n",
    "    elif x['tag'] == 'table':\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "    elif x['tag'] == 'tr':\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "        yield '\\n'\n",
    "    elif x['tag'] == 'th' or x['tag'] == 'td':\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "        yield ' | '\n",
    "    else:\n",
    "        print(x)\n",
    "        assert 0\n",
    "\n",
    "\n",
    "def parse_struct_meta(imistruct):\n",
    "    if type(imistruct) is str:\n",
    "        yield imistruct\n",
    "    elif type(imistruct) is dict:\n",
    "        yield from parse_struct(imistruct)\n",
    "    elif type(imistruct) is list:\n",
    "        for x in imistruct:\n",
    "            yield from parse_struct(x)\n",
    "    else:\n",
    "        print(imistruct)\n",
    "        assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "functioning-claim",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:13.697240Z",
     "start_time": "2022-09-23T00:25:03.647426Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lingual, JMdict\n",
      "Lingual, 新世纪日汉双解大辞典\n",
      "Lingual, Weblio 古語辞典\n",
      "Lingual, デジタル大辞泉\n",
      "Lingual, ハイブリッド新辞林\n",
      "Lingual, 三省堂 必携類語実用辞典\n",
      "Lingual, 大辞林 第三版\n",
      "Lingual, 学研 四字熟語辞典\n",
      "Lingual, 実用日本語表現辞典\n",
      "Lingual, 岩波国語辞典 第六版\n",
      "Lingual, 広辞苑 第七版\n",
      "Lingual, 故事ことわざの辞典\n",
      "Lingual, 新明解四字熟語辞典\n",
      "Lingual, 新明解国語辞典 第五版\n",
      "Lingual, どんなときどう使う 日本語表現文型辞典\n",
      "Lingual, 旺文社国語辞典 第十一版 画像無し\n",
      "Lingual, 明鏡国語辞典 第二版\n",
      "Lingual, 語源由来辞典\n"
     ]
    }
   ],
   "source": [
    "jpdc = {}\n",
    "dangling = {}\n",
    "for dir in os.listdir('jisho'):\n",
    "    if 'lingual' in dir:\n",
    "        index = json.load(open('jisho/'+dir+'/index.json', 'r'))\n",
    "        for j in filter(lambda x: 'term_bank' in x, os.listdir('jisho/'+dir)):\n",
    "            for term in json.load(open('jisho/'+dir+'/'+j, 'r')):\n",
    "                word, yomikata, _, _, weight, imi, _, _ = term\n",
    "                if '{{' in word:\n",
    "                    continue\n",
    "                if all(map(lambda x: x in katakana or x == '・', word)):\n",
    "                    word = word.replace('・', '')\n",
    "                if all(map(lambda x: ord(x) in latin, word)) and len(word) > 1:\n",
    "                    if yomikata != '' and all(map(lambda x: x in katakana, yomikata)):\n",
    "                        word = yomikata\n",
    "                if yomikata == '':\n",
    "                    yomikata = word\n",
    "                if all(map(lambda x: x in hiragana, word)) and word != yomikata:\n",
    "                    continue\n",
    "                if len(imi) > 1:\n",
    "                    assert imi[1]['type'] == 'image'\n",
    "                if not type(imi[0]) is str:\n",
    "                    assert imi[0]['type'] == 'structured-content'\n",
    "                    imi[0] = imi[0]['content'][0]+'\\n' + \\\n",
    "                        ''.join(parse_struct_meta(imi[0]['content'][1:]))\n",
    "                if weight < 0:\n",
    "                    weight = weight/8\n",
    "                imilen = len(imi[0]) - len(word)\n",
    "                imilen = (imilen - (len(yomikata) if yomikata !=\n",
    "                          word else 0)) if imilen > len(yomikata) else imilen\n",
    "                weight += math.sqrt(imilen) / \\\n",
    "                    (200 if index['title'] == 'JMdict' else 100)\n",
    "                if not all(map(lambda x: x in katakana or x in hiragana, yomikata)):\n",
    "                    currentdc = dangling\n",
    "                    currentkey = word\n",
    "                else:\n",
    "                    yomikata = ''.join(\n",
    "                        map(lambda x: x['hira'], kks.convert(yomikata)))\n",
    "                    currentdc = jpdc\n",
    "                    currentkey = (word, yomikata)\n",
    "                if currentkey in currentdc:\n",
    "                    if index['title'] not in currentdc[currentkey][1]:\n",
    "                        currentdc[currentkey][1][index['title']] = []\n",
    "                    if imi[0] not in currentdc[currentkey][1][index['title']]:\n",
    "                        currentdc[currentkey][1][index['title']].append(imi[0])\n",
    "                        currentdc[currentkey][0] += weight + 5\n",
    "                else:\n",
    "                    currentdc[currentkey] = [weight, {index['title']:[imi[0]]}]\n",
    "        print(f\"Lingual, {index['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "babd7f9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:13.874676Z",
     "start_time": "2022-09-23T00:28:13.699583Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try to fix incorrectly merged/splitted entries\n",
    "toRemove = set()\n",
    "toAdd = {}\n",
    "for word, yomikata in jpdc:\n",
    "    if '・' in word:\n",
    "        flag = \"UND\"\n",
    "        for w in word.split('・'):\n",
    "            if (w, yomikata) in jpdc:\n",
    "                if \"デジタル大辞泉\" in jpdc[(w, yomikata)][1]:\n",
    "                    flag = \"OK\"\n",
    "                elif \"デジタル大辞泉\" in jpdc[(word, yomikata)][1]:\n",
    "                    if flag == \"UND\":\n",
    "                        flag = \"BAD\"\n",
    "        if flag == \"BAD\":\n",
    "            for w in word.split('・'):\n",
    "                if (w, yomikata) in jpdc:\n",
    "                    temp = jpdc[(w, yomikata)]\n",
    "                    toRemove.add((w, yomikata))\n",
    "                    jpdc[(word, yomikata)][0] += temp[0]\n",
    "                    for k, v in temp[1].items():\n",
    "                        if k not in jpdc[(word, yomikata)][1]:\n",
    "                            jpdc[(word, yomikata)][1][k] = v\n",
    "                        else:\n",
    "                            for vv in v:\n",
    "                                if vv not in jpdc[(word, yomikata)][1][k]:\n",
    "                                    jpdc[(word, yomikata)][1][k].append(vv)\n",
    "        elif flag == \"OK\":\n",
    "            temp = jpdc[(word, yomikata)]\n",
    "            toRemove.add((word, yomikata))\n",
    "            for w in word.split('・'):\n",
    "                if (w, yomikata) in jpdc:\n",
    "                    jpdc[(w, yomikata)][0] += temp[0]\n",
    "                    for k, v in temp[1].items():\n",
    "                        if k not in jpdc[(w, yomikata)][1]:\n",
    "                            jpdc[(w, yomikata)][1][k] = v\n",
    "                        else:\n",
    "                            for vv in v:\n",
    "                                if vv not in jpdc[(word, yomikata)][1][k]:\n",
    "                                    jpdc[(word, yomikata)][1][k].append(vv)\n",
    "                else:\n",
    "                    toAdd[(w, yomikata)] = temp\n",
    "for k in toRemove:\n",
    "    del jpdc[k]\n",
    "for k in toAdd:\n",
    "    jpdc[k] = toAdd[k].copy()\n",
    "\n",
    "for term in [('ごいちろくぐんじくーでたー', ['五', '一六軍事クーデター']), ('によんでぃー', ['2']), ('よんいちくがくせいかくめい', ['四', '一九学生革命']), ('にいにいろくじけん', ['二', '二六事件']), ('ににはちじけん', ['二', '二八事件']), ('ぴーえむにてんご', ['5', 'PM2'])]:\n",
    "    yomi, ws = term\n",
    "    for w in ws:\n",
    "        del jpdc[(w, yomi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bound-tiger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:17.772339Z",
     "start_time": "2022-09-23T00:28:13.877077Z"
    }
   },
   "outputs": [],
   "source": [
    "words = {}\n",
    "yomikatas = {}\n",
    "for word, yomikata in jpdc:\n",
    "    if word not in words:\n",
    "        words[word] = [[jpdc[(word, yomikata)][0], yomikata]]\n",
    "    else:\n",
    "        words[word].append([jpdc[(word, yomikata)][0], yomikata])\n",
    "    if yomikata not in yomikatas:\n",
    "        yomikatas[yomikata] = [[jpdc[(word, yomikata)][0], word]]\n",
    "    else:\n",
    "        yomikatas[yomikata].append([jpdc[(word, yomikata)][0], word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f463b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:17.933400Z",
     "start_time": "2022-09-23T00:28:17.774478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fix dangling entries\n",
    "for w in dangling:\n",
    "    if w in words:\n",
    "        if len(words[w]) == 1 or len(w) == 1:\n",
    "            for yw in words[w]:\n",
    "                keys = (w, yw[1])\n",
    "                jpdc[keys][0] += dangling[w][0]\n",
    "                yw[0] += dangling[w][0]\n",
    "                for t in yomikatas[keys[1]]:\n",
    "                    if t[1] == w:\n",
    "                        t[0] += dangling[w][0]\n",
    "                for books in dangling[w][1]:\n",
    "                    if books not in jpdc[keys][1]:\n",
    "                        jpdc[keys][1][books] = []\n",
    "                    for imis in dangling[w][1][books]:\n",
    "                        if imis not in jpdc[keys][1][books]:\n",
    "                            jpdc[keys][1][books].append(imis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a2efcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:18.890552Z",
     "start_time": "2022-09-23T00:28:17.935229Z"
    }
   },
   "outputs": [],
   "source": [
    "for word, yomikata in jpdc:\n",
    "    if word in freqs:\n",
    "        jpdc[(word, yomikata)][0] += freqs[word]\n",
    "    if (word, yomikata) in freqs:\n",
    "        jpdc[(word, yomikata)][0] += freqs[(word, yomikata)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05541f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:19.962328Z",
     "start_time": "2022-09-23T00:28:18.893058Z"
    }
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    words[word] = sorted(words[word], key=lambda x: x[0], reverse=True)\n",
    "for yomikata in yomikatas:\n",
    "    yomikatas[yomikata] = sorted(\n",
    "        yomikatas[yomikata], key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ca579b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:24.682318Z",
     "start_time": "2022-09-23T00:28:19.964279Z"
    }
   },
   "outputs": [],
   "source": [
    "# try to merge same term\n",
    "for yomikata in yomikatas:\n",
    "    for i in range(len(yomikatas[yomikata])):\n",
    "        wordi = yomikatas[yomikata][i][1]\n",
    "        if all(map(lambda x: x in katakana or x in hiragana, wordi)) and len(yomikatas[yomikata]) > 2:\n",
    "            continue\n",
    "        imis = jpdc[(wordi, yomikata)][1]\n",
    "        for j in range(i+1, len(yomikatas[yomikata])):\n",
    "            wordj = yomikatas[yomikata][j][1]\n",
    "            if all(map(lambda x: x in katakana or x in hiragana, wordj)) and len(yomikatas[yomikata]) > 2:\n",
    "                continue\n",
    "            imisj = jpdc[(wordj, yomikata)][1]\n",
    "            flag = False\n",
    "            for k in set(imis.keys()).intersection(set(imisj.keys())):\n",
    "                flag = True\n",
    "                if imis[k] != imisj[k]:\n",
    "                    flag = False\n",
    "                    break\n",
    "            if flag:\n",
    "                for k in imisj:\n",
    "                    imis[k] = imisj[k]\n",
    "                jpdc[(wordj, yomikata)][1] = imis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5392e583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:27.262855Z",
     "start_time": "2022-09-23T00:28:24.686175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manual one-way merge some frequently used pairs\n",
    "oneway_pairs = [('する', '為る'), ('など', '等'), ('まで', '迄'), ('について', 'に就いて'), ('ではない', 'では無い'), ('ほど', '程'), ('てしまう', 'て仕舞う'), ('ながら', '乍ら'), ('そして', '然して'), ('によって', 'に因って'), ('による', 'に依る'), ('べし', '可し'), ('ことができる', '事ができる'), ('ことになる', '事になる'), ('つく', '付く'), ('ばかり', '許り'), ('にとって', 'に取って'), ('かもしれない', 'かも知れない'), ('どうして', '如何して'), ('といった', 'と言った'), ('ことがある', '事がある'), ('どうしても', '如何しても'), ('ことにする', '事にする'), ('ことはない', '事はない'), ('あんた', '貴方'), ('によると', 'に依ると'), ('こっち', '此方'), ('をもって', 'を以て'), ('とる', '取る'), ('によれば', 'に依れば'), ('さっき', '先'), ('とはいえ', 'とは言え'), ('といっても', 'と言っても'), ('にわたって', 'に渡って'), ('こととなる', '事となる'), ('あちこち', '彼方此方'), ('なる', '成る'), ('までもない', 'までも無い'), ('による', 'に依る'), ('にわたり', 'に渡り'), ('ここ', '此処')]\n",
    "for yomi in yomikatas:\n",
    "    if len(yomikatas[yomi]) == 2:\n",
    "        if yomikatas[yomi][0][1] == yomi:\n",
    "            if any(map(is_cjk, yomikatas[yomi][1][1])):\n",
    "                oneway_pairs.append((yomi,yomikatas[yomi][1][1]))\n",
    "        if yomikatas[yomi][1][1] == yomi:\n",
    "            if any(map(is_cjk, yomikatas[yomi][0][1])):\n",
    "                oneway_pairs.append((yomi,yomikatas[yomi][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c534980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:27.320456Z",
     "start_time": "2022-09-23T00:28:27.264875Z"
    }
   },
   "outputs": [],
   "source": [
    "for pair in oneway_pairs:\n",
    "    for k in jpdc[(pair[1],pair[0])][1]:\n",
    "        if k not in jpdc[(pair[0], pair[0])][1]:\n",
    "            jpdc[(pair[0], pair[0])][1][k] = []\n",
    "        for imi in jpdc[(pair[1],pair[0])][1][k]:\n",
    "            if imi not in jpdc[(pair[0], pair[0])][1][k]:\n",
    "                jpdc[(pair[0], pair[0])][1][k].append(imi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2921b4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:28:29.059556Z",
     "start_time": "2022-09-23T00:28:27.322408Z"
    }
   },
   "outputs": [],
   "source": [
    "weightlist = list(map(lambda x: x[0], jpdc.values()))\n",
    "weightlist.sort()\n",
    "for w in jpdc:\n",
    "    jpdc[w].append(len(weightlist)-bisect.bisect_right(weightlist, jpdc[w][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ad3408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:09.154826Z",
     "start_time": "2022-09-23T00:28:29.061427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitches, Kanjium Pitch Accents\n",
      "Pitches, アクセント辞典\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir('jisho/'):\n",
    "    if 'Pitch Accent' in dir:\n",
    "        index = json.load(open('jisho/'+dir+'/index.json', 'r'))\n",
    "        for j in filter(lambda x: 'term_meta_bank' in x, os.listdir('jisho/'+dir)):\n",
    "            for term in json.load(open('jisho/'+dir+'/'+j, 'r')):\n",
    "                word, _, pitch = term\n",
    "                assert _ == 'pitch'\n",
    "                yomi = ''.join(\n",
    "                    map(lambda x: x['hira'], kks.convert(pitch['reading'])))\n",
    "                if (word, yomi) in jpdc:\n",
    "                    if len(jpdc[(word, yomi)]) == 3:\n",
    "                        jpdc[(word, yomi)].append(set())\n",
    "                    for p in pitch['pitches']:\n",
    "                        jpdc[(word, yomi)][3].add(p['position'])\n",
    "        print(f\"Pitches, {index['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0130f158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:19.872263Z",
     "start_time": "2022-09-23T00:29:09.156644Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(jpdc, open('jpdc.pkl', 'wb'))\n",
    "pickle.dump(yomikatas, open('yomikatas.pkl', 'wb'))\n",
    "pickle.dump(words, open('words.pkl', 'wb'))\n",
    "pickle.dump(freqs, open('freqs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e68c781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:19.877171Z",
     "start_time": "2022-09-23T00:29:19.874621Z"
    }
   },
   "outputs": [],
   "source": [
    "#jpdc = pickle.load(open('jpdc.pkl', 'rb'))\n",
    "#yomikatas = pickle.load(open('yomikatas.pkl', 'rb'))\n",
    "#words = pickle.load(open('words.pkl', 'rb'))\n",
    "#freqs = pickle.load(open('freqs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61493d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:27.155806Z",
     "start_time": "2022-09-23T00:29:19.879275Z"
    }
   },
   "outputs": [],
   "source": [
    "cw = {}\n",
    "for w, yomi in jpdc:\n",
    "    for c in w:\n",
    "        if is_cjk(c):\n",
    "            if c not in cw:\n",
    "                cw[c] = 0\n",
    "            cw[c] += jpdc[(w, yomi)][0]\n",
    "\n",
    "cwth = sorted(cw.items(), key=lambda x: x[1], reverse=True)[2600][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b834b0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:27.249880Z",
     "start_time": "2022-09-23T00:29:27.157590Z"
    }
   },
   "outputs": [],
   "source": [
    "univar = []\n",
    "for l in list(filter(lambda x: len(x) > 4 and x[0] != '#', open('unihan/Unihan_Variants.txt').read().split('\\n'))):\n",
    "    l = l.split('\\t')\n",
    "    if l[1] == 'kSpecializedSemanticVariant':\n",
    "        continue\n",
    "    a = chr(int(l[0][2:], 16))\n",
    "    for b in l[2].split(' '):\n",
    "        b = chr(int(b.split('<')[0][2:], 16))\n",
    "        assert is_cjk(a) and is_cjk(b)\n",
    "        univar.append((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "405978b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:27.258563Z",
     "start_time": "2022-09-23T00:29:27.252062Z"
    }
   },
   "outputs": [],
   "source": [
    "shinjitai = \"亜（亞） 悪（惡） 圧（壓） 囲（圍） 医（醫） 為（爲） 壱（壹） 逸（逸） 隠（隱） 栄（榮） 営（營） 衛（衞） 駅（驛） 謁（謁） 円（圓） 塩（鹽） 縁（緣） 艶（艷） 応（應） 欧（歐） 殴（毆） 桜（櫻） 奥（奧） 横（橫） 温（溫） 穏（穩） 仮（假） 価（價） 禍（禍） 画（畫） 会（會） 悔（悔） 海（海） 絵（繪） 壊（壞） 懐（懷） 慨（慨） 概（槪） 拡（擴） 殻（殼） 覚（覺） 学（學） 岳（嶽） 楽（樂） 喝（喝） 渇（渴） 褐（褐） 缶（罐） 巻（卷） 陥（陷） 勧（勸） 寛（寬） 漢（漢） 関（關） 歓（歡） 観（觀） 気（氣） 祈（祈） 既（既） 帰（歸） 亀（龜） 器（器） 偽（僞） 戯（戲） 犠（犧） 旧（舊） 拠（據） 挙（擧） 虚（虛） 峡（峽） 挟（挾） 狭（狹） 郷（鄕） 響（響） 暁（曉） 勤（勤） 謹（謹） 区（區） 駆（驅） 勲（勳） 薫（薰） 径（徑） 茎（莖） 恵（惠） 掲（揭） 渓（溪） 経（經） 蛍（螢） 軽（輕） 継（繼） 鶏（鷄） 芸（藝） 撃（擊） 欠（缺） 研（硏） 県（縣） 倹（儉） 剣（劍） 険（險） 圏（圈） 検（檢） 献（獻） 権（權） 顕（顯） 験（驗） 厳（嚴） 広（廣） 効（效） 恒（恆） 黄（黃） 鉱（鑛） 号（號） 国（國） 黒（黑） 穀（穀） 砕（碎） 済（濟） 斎（齋） 剤（劑） 殺（殺） 雑（雜） 参（參） 桟（棧） 蚕（蠶） 惨（慘） 賛（贊） 残（殘） 糸（絲） 祉（祉） 視（視） 歯（齒） 児（兒） 辞（辭） 湿（濕） 実（實） 写（寫） 社（社） 者（者） 煮（煮） 釈（釋） 寿（壽） 収（收） 臭（臭） 従（從） 渋（澁） 獣（獸） 縦（縱） 祝（祝） 粛（肅） 処（處） 暑（暑） 署（署） 緒（緖） 諸（諸） 叙（敍） 将（將） 祥（祥） 称（稱） 渉（涉） 焼（燒） 証（證） 奨（奬） 条（條） 状（狀） 乗（乘） 浄（淨） 剰（剩） 畳（疊） 縄（繩） 壌（壤） 嬢（孃） 譲（讓） 醸（釀） 触（觸） 嘱（囑） 神（神） 真（眞） 寝（寢） 慎（愼） 尽（盡） 図（圖） 粋（粹） 酔（醉） 穂（穗） 随（隨） 髄（髓） 枢（樞） 数（數） 瀬（瀨） 声（聲） 斉（齊） 静（靜） 窃（竊） 摂（攝） 節（節） 専（專） 浅（淺） 戦（戰） 践（踐） 銭（錢） 潜（潛） 繊（纖） 禅（禪） 祖（祖） 双（雙） 壮（壯） 争（爭） 荘（莊） 捜（搜） 挿（插） 巣（巢） 曽（曾） 痩（瘦） 装（裝） 僧（僧） 層（層） 総（總） 騒（騷） 増（增） 憎（憎） 蔵（藏） 贈（贈） 臓（臟） 即（卽） 属（屬） 続（續） 堕（墮） 対（對） 体（體） 帯（帶） 滞（滯） 台（臺） 滝（瀧） 択（擇） 沢（澤） 担（擔） 単（單） 胆（膽） 嘆（嘆） 団（團） 断（斷） 弾（彈） 遅（遲） 痴（癡） 虫（蟲） 昼（晝） 鋳（鑄） 著（著） 庁（廳） 徴（徵） 聴（聽） 懲（懲） 勅（敕） 鎮（鎭） 塚（塚） 逓（遞） 鉄（鐵） 点（點） 転（轉） 伝（傳） 都（都） 灯（燈） 当（當） 党（黨） 盗（盜） 稲（稻） 闘（鬭） 徳（德） 独（獨） 読（讀） 突（突） 届（屆） 難（難） 弐（貳） 悩（惱） 脳（腦） 覇（霸） 拝（拜） 廃（廢） 売（賣） 梅（梅） 麦（麥） 発（發） 髪（髮） 抜（拔） 繁（繁） 晩（晚） 蛮（蠻） 卑（卑） 秘（祕） 碑（碑） 浜（濱） 賓（賓） 頻（頻） 敏（敏） 瓶（甁） 侮（侮） 福（福） 払（拂） 仏（佛） 併（倂） 並（竝） 塀（塀） 餅（餠） 辺（邊） 変（變） 弁（辨） 弁（瓣） 弁（辯） 勉（勉） 歩（步） 宝（寶） 豊（豐） 褒（襃） 墨（墨） 翻（飜） 毎（每） 万（萬） 満（滿） 免（免） 麺（麵） 黙（默） 弥（彌） 訳（譯） 薬（藥） 与（與） 予（豫） 余（餘） 誉（譽） 揺（搖） 様（樣） 謡（謠） 来（來） 頼（賴） 乱（亂） 覧（覽） 欄（欄） 竜（龍） 隆（隆） 虜（虜） 両（兩） 猟（獵） 緑（綠） 涙（淚） 塁（壘） 類（類） 礼（禮） 励（勵） 戻（戾） 霊（靈） 齢（齡） 暦（曆） 歴（歷） 恋（戀） 練（練） 錬（鍊） 炉（爐） 労（勞） 郎（郞） 朗（朗） 廊（廊） 楼（樓） 録（錄） 湾（灣） 亘（亙） 凜（凛） 尭（堯） 巌（巖） 晃（晄） 桧（檜） 槙（槇） 渚（渚） 猪（豬） 琢（琢） 祢（禰） 祐（祐） 祷（禱） 禄（祿） 禎（禎） 穣（穰） 萌（萠） 遥（遙） 唖（啞） 頴（穎） 鴎（鷗） 撹（攪） 麹（麴） 鹸（鹼） 噛（嚙） 繍（繡） 蒋（蔣） 醤（醬） 曽（曾） 掻（搔） 痩（瘦） 祷（禱） 屏（屛） 并（幷） 桝（枡） 麺（麵） 沪（濾） 芦（蘆） 蝋（蠟） 弯（彎）\"\n",
    "for l in shinjitai.split(' '):\n",
    "    a = l[0]\n",
    "    b = l[2]\n",
    "    assert is_cjk(a) and is_cjk(b)\n",
    "    assert a != b\n",
    "    univar.append((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45ca6c7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:27.305409Z",
     "start_time": "2022-09-23T00:29:27.260548Z"
    }
   },
   "outputs": [],
   "source": [
    "for txt in os.listdir('sts-data'):\n",
    "    with open('sts-data/'+txt, 'r') as f:\n",
    "        for l in f.read().split('\\n'):\n",
    "            l = l.split('\\t')\n",
    "            if len(l) > 1:\n",
    "                a = l[0]\n",
    "                for b in l[1].split(' '):\n",
    "                    univar.append((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e782fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:27.345669Z",
     "start_time": "2022-09-23T00:29:27.307228Z"
    }
   },
   "outputs": [],
   "source": [
    "class DisjointSet(object):\n",
    "\n",
    "    def __init__(self, weight):\n",
    "        self.leader = {}  # maps a member to the group's leader\n",
    "        self.group = {}  # maps a group leader to the group (which is a set)\n",
    "        self.weight = weight\n",
    "\n",
    "    def comp(self, leadera, leaderb, groupa, groupb):\n",
    "        if leadera in self.weight:\n",
    "            if leaderb in self.weight:\n",
    "                return self.weight[leadera] < self.weight[leaderb]\n",
    "            else:\n",
    "                return False\n",
    "        elif leaderb in self.weight:\n",
    "            return True\n",
    "        else:\n",
    "            return len(groupa) < len(groupb)\n",
    "\n",
    "    def add(self, a, b):\n",
    "        if a not in self.leader:\n",
    "            self.leader[a] = a\n",
    "            self.group[a] = set([a])\n",
    "        if b not in self.leader:\n",
    "            self.leader[b] = b\n",
    "            self.group[b] = set([b])\n",
    "        leadera = self.leader.get(a)\n",
    "        leaderb = self.leader.get(b)\n",
    "        if leadera == leaderb:\n",
    "            return  # nothing to do\n",
    "        groupa = self.group[leadera]\n",
    "        groupb = self.group[leaderb]\n",
    "        if self.comp(leadera, leaderb, groupa, groupb):\n",
    "            a, leadera, groupa, b, leaderb, groupb = b, leaderb, groupb, a, leadera, groupa\n",
    "        groupa |= groupb\n",
    "        del self.group[leaderb]\n",
    "        for k in groupb:\n",
    "            self.leader[k] = leadera\n",
    "\n",
    "\n",
    "ds = DisjointSet(cw)\n",
    "for a, b in univar:\n",
    "    ds.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13093e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:27.360571Z",
     "start_time": "2022-09-23T00:29:27.347629Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in ds.group.copy():\n",
    "    if x not in cw:\n",
    "        del ds.group[x]\n",
    "for x in ds.leader.copy():\n",
    "    if ds.leader[x] not in cw:\n",
    "        del ds.leader[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caeab813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:27.372164Z",
     "start_time": "2022-09-23T00:29:27.362454Z"
    }
   },
   "outputs": [],
   "source": [
    "cjconvert = {}\n",
    "for x in ds.leader:\n",
    "    if (x not in cw or cw[x] < cwth) and x != ds.leader[x]:\n",
    "        cjconvert[x] = ds.leader[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af616726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:27.384876Z",
     "start_time": "2022-09-23T00:29:27.374444Z"
    }
   },
   "outputs": [],
   "source": [
    "convertjs = json.dumps(cjconvert, ensure_ascii=False)\n",
    "with open('../js/cjconvert.js', 'w') as f:\n",
    "    f.write(f\"const cjdc = {convertjs};\\n\")\n",
    "    f.write(\n",
    "        \"function cj_convert(s) {return s.split('').map(c=>cjdc[c]||c).join('');}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "356b2420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:28.087043Z",
     "start_time": "2022-09-23T00:29:27.387498Z"
    }
   },
   "outputs": [],
   "source": [
    "ml = 0\n",
    "for w in words:\n",
    "    if any(map(lambda x: x in cjconvert, w)):\n",
    "        if ml < len(w):\n",
    "            ml = len(w)\n",
    "assert max(map(len, words.keys())) < 100 and max(\n",
    "    map(len, yomikatas.keys())) < 60 and ml < 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be59ccc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:28.097697Z",
     "start_time": "2022-09-23T00:29:28.088885Z"
    }
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"../db/arujisho.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a1efa39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:29:28.136027Z",
     "start_time": "2022-09-23T00:29:28.100103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fe8c771ae40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('''CREATE VIRTUAL TABLE IF NOT EXISTS jpdc USING fts4(word NVARCHAR(100) NOT NULL, yomikata NVARCHAR(60) NOT NULL, romaji VARCHAR(108) NOT NULL,\n",
    "            freqRank INTEGER NOT NULL NOT INDEXED,\n",
    "            rword NVARCHAR(100) NOT NULL, ryomikata NVARCHAR(60) NOT NULL, rromaji VARCHAR(108) NOT NULL,\n",
    "            pitchData VARCHAR(20) NOT INDEXED,\n",
    "            origForm NVARCHAR(40) NOT INDEXED,\n",
    "            idex INTEGER NOT NULL)''')\n",
    "cur.execute(\n",
    "    '''CREATE TABLE IF NOT EXISTS imis (imi TEXT NOT NULL, orig TEXT NOT NULL)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09720aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:33:07.187013Z",
     "start_time": "2022-09-23T00:29:28.138432Z"
    }
   },
   "outputs": [],
   "source": [
    "dups = {}\n",
    "c = 1\n",
    "for w, v in sorted(jpdc.items(), key=lambda x: x[1][2]):\n",
    "    jData = json.dumps(v[1], ensure_ascii=False, sort_keys=True)\n",
    "    if jData not in dups:\n",
    "        cur.execute('INSERT INTO imis VALUES (?, ?)', (jData, w[0]))\n",
    "        dups[jData] = (c, w[0])\n",
    "        c += 1\n",
    "    romaji = ''.join(\n",
    "        map(lambda x: x['hepburn'], kks.convert(w[1]))).replace(\"'\", '')\n",
    "    word = ''.join(\n",
    "        map(lambda x: x if x not in cjconvert else cjconvert[x], w[0]))\n",
    "    cur.execute('INSERT INTO jpdc VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',\n",
    "                (word, w[1], romaji, v[2],\n",
    "                 word[::-1], w[1][::-1], romaji[::-1],\n",
    "                 str(sorted(list(v[3]))) if len(v) > 3 else '', '' if word == w[0] else w[0], dups[jData][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48522bf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T00:33:08.320757Z",
     "start_time": "2022-09-23T00:33:07.190548Z"
    }
   },
   "outputs": [],
   "source": [
    "con.commit()\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
