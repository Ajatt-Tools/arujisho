{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb715277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pykakasi\n",
    "import re\n",
    "import bisect\n",
    "import sqlite3\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4397d0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "katakana = ''.join(map(chr, range(0x30a1, 0x30fb))) + 'ー' + '々'\n",
    "hiragana = ''.join(map(chr, range(0x3041, 0x3097)))\n",
    "cjkranges = [\n",
    "    # compatibility ideographs\n",
    "    {\"from\": ord(u\"\\u3300\"), \"to\": ord(u\"\\u33ff\")},\n",
    "    # compatibility ideographs\n",
    "    {\"from\": ord(u\"\\ufe30\"), \"to\": ord(u\"\\ufe4f\")},\n",
    "    # compatibility ideographs\n",
    "    {\"from\": ord(u\"\\uf900\"), \"to\": ord(u\"\\ufaff\")},\n",
    "    # compatibility ideographs\n",
    "    {\"from\": ord(u\"\\U0002F800\"), \"to\": ord(u\"\\U0002fa1f\")},\n",
    "    # cjk radicals supplement\n",
    "    {\"from\": ord(u\"\\u2e80\"), \"to\": ord(u\"\\u2eff\")},\n",
    "    {\"from\": ord(u\"\\u3400\"), \"to\": ord(u\"\\u9fff\")},\n",
    "    {\"from\": ord(u\"\\U00020000\"), \"to\": ord(u\"\\U0002a6df\")},\n",
    "    {\"from\": ord(u\"\\U0002a700\"), \"to\": ord(u\"\\U0002b73f\")},\n",
    "    {\"from\": ord(u\"\\U0002b740\"), \"to\": ord(u\"\\U0002b81f\")},\n",
    "    {\"from\": ord(u\"\\U0002b820\"), \"to\": ord(u\"\\U0002ceaf\")},\n",
    "    {\"from\": ord(u\"\\U0002ceb0\"), \"to\": ord(u\"\\U0002ebef\")},\n",
    "    {\"from\": ord(u\"\\U0002f800\"), \"to\": ord(u\"\\U0002fa1f\")},\n",
    "    {\"from\": ord(u\"\\U00030000\"), \"to\": ord(u\"\\U0003134f\")},\n",
    "]\n",
    "\n",
    "\n",
    "def is_cjk(char):\n",
    "    return any([range[\"from\"] <= ord(char) <= range[\"to\"] for range in cjkranges])\n",
    "\n",
    "\n",
    "latin = range(0x41, 0x17f)\n",
    "kks = pykakasi.kakasi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf1105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting Zipf-Mandelbrot distribution\n",
    "def zipf(x, a, b, c):\n",
    "    return np.power(2, c-a*np.log2(b+x)\n",
    "                    # normalize so that zipf_fit(500000) == 1\n",
    "                    - 3.9637728168533783)\n",
    "\n",
    "\n",
    "def zipf_fit(x):\n",
    "    return np.where(x < 2666, zipf(x, *[1.07328228,  0.39173476, 31.30810071]),\n",
    "                    np.where(x < 9460, zipf(x, *[1.69009214, 787.97415275,  38.95873033]),\n",
    "                             zipf(x, *[2.63859003e+00, 9.76268153e+03, 5.39900314e+01])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0936bf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq, BCCWJ-LUW, 10\n",
      "Freq, CC100, 10\n",
      "Freq, Innocent Ranked, 0.1\n",
      "Freq, JPDB, 1\n",
      "Freq, Netflix, 0.5\n",
      "Freq, Novels, 0.5\n",
      "Freq, TWC, 2\n",
      "Freq, Wikipedia, 1\n",
      "Freq, 国語辞典, 0.8\n"
     ]
    }
   ],
   "source": [
    "use_cache = False\n",
    "if os.path.exists('words.pkl'):\n",
    "    words = pickle.load(open('words.pkl', 'rb'))\n",
    "    use_cache = True\n",
    "\n",
    "freqs = {}\n",
    "lweights = {}\n",
    "for dir in os.listdir('jisho'):\n",
    "    if 'Freq' in dir:\n",
    "        index = json.load(open('jisho/'+dir+'/index.json', 'r'))\n",
    "        lweights[index['title']] = 1 if 'weight' not in index else index['weight']\n",
    "        for j in filter(lambda x: 'term_meta_bank' in x, os.listdir('jisho/'+dir)):\n",
    "            for term in json.load(open('jisho/'+dir+'/'+j, 'r')):\n",
    "                weight = 1\n",
    "                word, _, freq = term\n",
    "                assert _ == 'freq'\n",
    "                wk = word\n",
    "                if type(freq) is dict and 'reading' in freq:\n",
    "                    yomikata = freq['reading']\n",
    "                    if not all(map(lambda x: x in hiragana or x in katakana, word)):\n",
    "                        if not all(map(lambda x: x in hiragana, yomikata)):\n",
    "                            yomikata = ''.join(\n",
    "                                map(lambda x: x['hira'], kks.convert(yomikata)))\n",
    "                        wk = (word, yomikata)\n",
    "                        weight *= 2\n",
    "                    else:\n",
    "                        weight *= 1.5\n",
    "                    freq = freq['frequency']\n",
    "                elif all(map(lambda x: x in hiragana or x in katakana, word)):\n",
    "                    weight *= 1.5\n",
    "                if type(freq) is dict and 'value' in freq:\n",
    "                    if not all(map(lambda x: x in hiragana or x in katakana, word)):\n",
    "                        if \"㋕\" in freq['displayValue']:\n",
    "                            weight *= 0.5\n",
    "                    freq = freq['value']\n",
    "                if use_cache:\n",
    "                    if type(wk) is str and (not all(map(lambda x: x in hiragana or x in katakana, wk))) and wk in words and len(words[wk]) == 1:\n",
    "                        wk = (wk, words[wk][0][1])\n",
    "                        weight *= 2\n",
    "                if wk not in freqs:\n",
    "                    freqs[wk] = {}\n",
    "                if index['title'] not in freqs[wk]:\n",
    "                    freqs[wk][index['title']] = 0\n",
    "                freqs[wk][index['title']] += float(zipf_fit(freq))*weight\n",
    "        print(\n",
    "            f\"Freq, {index['title']}, {lweights[index['title']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76943b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hodges_Lehmann(data, weight):\n",
    "    temp = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i, len(data)):\n",
    "            temp.append((data[i]*weight[i]+data[j] *\n",
    "                        weight[j])/(weight[i]+weight[j]))\n",
    "    return statistics.median(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a60291e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for wk in freqs:\n",
    "    l = []\n",
    "    w = []\n",
    "    for title in lweights:\n",
    "        if title in freqs[wk]:\n",
    "            l.append(freqs[wk][title])\n",
    "        else:\n",
    "            l.append(0)\n",
    "        w.append(lweights[title])\n",
    "    freqs[wk] = Hodges_Lehmann(\n",
    "        l, w)/2 + sum(map(lambda x: x[0]*x[1], zip(l, w)))/sum(w)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598f71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_struct(x):\n",
    "    if type(x) is str:\n",
    "        yield x\n",
    "    elif x['tag'] == 'img':\n",
    "        pass\n",
    "    elif x['tag'] == 'div':\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "        yield '\\n'\n",
    "    elif x['tag'] == 'span':\n",
    "        yield '('\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "        yield ')'\n",
    "    elif x['tag'] == 'a':\n",
    "        assert type(x['content']) is str\n",
    "        yield f\"【{x['content']}】\"\n",
    "    elif x['tag'] == 'br':\n",
    "        yield '\\n'\n",
    "    elif x['tag'] == 'ruby':\n",
    "        yield f\"({x['content'][0]})\"\n",
    "    elif x['tag'] == 'table':\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "    elif x['tag'] == 'tr':\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "        yield '\\n'\n",
    "    elif x['tag'] == 'th' or x['tag'] == 'td':\n",
    "        yield from parse_struct_meta(x['content'])\n",
    "        yield ' | '\n",
    "    else:\n",
    "        print(x)\n",
    "        assert 0\n",
    "\n",
    "\n",
    "def parse_struct_meta(imistruct):\n",
    "    if type(imistruct) is str:\n",
    "        yield imistruct\n",
    "    elif type(imistruct) is dict:\n",
    "        yield from parse_struct(imistruct)\n",
    "    elif type(imistruct) is list:\n",
    "        for x in imistruct:\n",
    "            yield from parse_struct(x)\n",
    "    else:\n",
    "        print(imistruct)\n",
    "        assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2903f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lingual, JMdict, 0.23807886552931884-104.24787653403847\n",
      "Lingual, Weblio 古語辞典, 20.03-20.540092584655632\n",
      "Lingual, デジタル大辞泉, 20.01-20.793977329651167\n",
      "Lingual, ハイブリッド新辞林, 21.22-23.061074958189486\n",
      "Lingual, 三省堂 必携類語実用辞典, 20.02-20.299666481275434\n",
      "Lingual, 大辞林 第三版, 0.15567764362830164-100.18544003745318\n",
      "Lingual, 学研 四字熟語辞典, 20.04-20.228691932520587\n",
      "Lingual, 実用日本語表現辞典, 20.02828427124746-20.36207733980463\n",
      "Lingual, 岩波国語辞典 第六版, 20.022360679774998-20.6187891401762\n",
      "Lingual, 広辞苑 第七版, 20.0-20.586259328283994\n",
      "Lingual, 故事ことわざの辞典, 20.02-20.248193472919816\n",
      "Lingual, 新明解四字熟語辞典, 20.017320508075688-20.26038433132583\n",
      "Lingual, 新明解国語辞典 第五版, 20.017320508075688-20.27964262908219\n",
      "Lingual, どんなときどう使う 日本語表現文型辞典, 20.017320508075688-20.40607881008494\n",
      "Lingual, 旺文社国語辞典 第十一版 画像無し, 20.034641016151376-20.51484937025383\n",
      "Lingual, 明鏡国語辞典 第二版, 19.60049875621121-20.70689461732284\n",
      "Lingual, 語源由来辞典, 20.170293863659264-20.564092191046818\n"
     ]
    }
   ],
   "source": [
    "jpdc = {}\n",
    "dangling = {}\n",
    "for dir in os.listdir('jisho'):\n",
    "    if 'lingual' in dir:\n",
    "        index = json.load(open('jisho/'+dir+'/index.json', 'r'))\n",
    "        minw = 2**32\n",
    "        maxw = -2**32\n",
    "        for j in filter(lambda x: 'term_bank' in x, os.listdir('jisho/'+dir)):\n",
    "            for term in json.load(open('jisho/'+dir+'/'+j, 'r')):\n",
    "                word, yomikata, _, _, weight, imi, _, _ = term\n",
    "                if '{{' in word:\n",
    "                    continue\n",
    "                if all(map(lambda x: x in katakana or x == '・', word)):\n",
    "                    word = word.replace('・', '')\n",
    "                if all(map(lambda x: ord(x) in latin, word)) and len(word) > 1:\n",
    "                    if yomikata != '' and all(map(lambda x: x in katakana, yomikata)):\n",
    "                        word = yomikata\n",
    "                if yomikata == '':\n",
    "                    yomikata = word\n",
    "                if all(map(lambda x: x in hiragana, word)) and word != yomikata:\n",
    "                    continue\n",
    "                if len(imi) > 1:\n",
    "                    assert imi[1]['type'] == 'image'\n",
    "                if not type(imi[0]) is str:\n",
    "                    assert imi[0]['type'] == 'structured-content'\n",
    "                    imi[0] = imi[0]['content'][0]+'\\n' + \\\n",
    "                        ''.join(parse_struct_meta(imi[0]['content'][1:]))\n",
    "                imi[0] = imi[0].rstrip()\n",
    "                imilen = len(imi[0]) - len(word)\n",
    "                imilen = (imilen - (len(yomikata) if yomikata !=\n",
    "                          word else 0)) if imilen > len(yomikata) else imilen\n",
    "                weight = weight / 10 + 20 + \\\n",
    "                    math.sqrt(imilen) / \\\n",
    "                    (200 if index['title'] == 'JMdict' else 100)\n",
    "                assert weight > 0\n",
    "                yomikata = yomikata.replace('・', '')\n",
    "                if not all(map(lambda x: x in katakana or x in hiragana, yomikata)):\n",
    "                    currentdc = dangling\n",
    "                    currentkey = word\n",
    "                else:\n",
    "                    yomikata = ''.join(\n",
    "                        map(lambda x: x['hira'], kks.convert(yomikata)))\n",
    "                    currentdc = jpdc\n",
    "                    currentkey = (word, yomikata)\n",
    "                if currentkey in currentdc:\n",
    "                    if index['title'] not in currentdc[currentkey][1]:\n",
    "                        currentdc[currentkey][1][index['title']] = []\n",
    "                    if imi[0] not in currentdc[currentkey][1][index['title']]:\n",
    "                        currentdc[currentkey][1][index['title']].append(imi[0])\n",
    "                        currentdc[currentkey][0] += weight + 5\n",
    "                else:\n",
    "                    currentdc[currentkey] = [weight, {index['title']:[imi[0]]}]\n",
    "                if weight > maxw:\n",
    "                    maxw = weight\n",
    "                if weight < minw:\n",
    "                    minw = weight\n",
    "        print(f\"Lingual, {index['title']}, {minw}-{maxw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29325e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fix incorrectly merged/splitted entries\n",
    "toRemove = set()\n",
    "toAdd = {}\n",
    "for word, yomikata in jpdc:\n",
    "    if '・' in word:\n",
    "        flag = \"UND\"\n",
    "        for w in word.split('・'):\n",
    "            if (w, yomikata) in jpdc:\n",
    "                if \"デジタル大辞泉\" in jpdc[(w, yomikata)][1]:\n",
    "                    flag = \"OK\"\n",
    "                elif \"デジタル大辞泉\" in jpdc[(word, yomikata)][1]:\n",
    "                    if flag == \"UND\":\n",
    "                        flag = \"BAD\"\n",
    "        if flag == \"BAD\":\n",
    "            for w in word.split('・'):\n",
    "                if (w, yomikata) in jpdc:\n",
    "                    temp = jpdc[(w, yomikata)]\n",
    "                    toRemove.add((w, yomikata))\n",
    "                    jpdc[(word, yomikata)][0] += temp[0]\n",
    "                    for k, v in temp[1].items():\n",
    "                        if k not in jpdc[(word, yomikata)][1]:\n",
    "                            jpdc[(word, yomikata)][1][k] = v\n",
    "                        else:\n",
    "                            for vv in v:\n",
    "                                if vv not in jpdc[(word, yomikata)][1][k]:\n",
    "                                    jpdc[(word, yomikata)][1][k].append(vv)\n",
    "        elif flag == \"OK\":\n",
    "            temp = jpdc[(word, yomikata)]\n",
    "            toRemove.add((word, yomikata))\n",
    "            for w in word.split('・'):\n",
    "                if (w, yomikata) in jpdc:\n",
    "                    jpdc[(w, yomikata)][0] += temp[0]\n",
    "                    for k, v in temp[1].items():\n",
    "                        if k not in jpdc[(w, yomikata)][1]:\n",
    "                            jpdc[(w, yomikata)][1][k] = v\n",
    "                        else:\n",
    "                            for vv in v:\n",
    "                                if vv not in jpdc[(word, yomikata)][1][k]:\n",
    "                                    jpdc[(word, yomikata)][1][k].append(vv)\n",
    "                else:\n",
    "                    toAdd[(w, yomikata)] = temp\n",
    "for k in toRemove:\n",
    "    del jpdc[k]\n",
    "for k in toAdd:\n",
    "    jpdc[k] = toAdd[k].copy()\n",
    "\n",
    "for term in [('ごいちろくぐんじくーでたー', ['五', '一六軍事クーデター']), ('によんでぃー', ['2']), ('よんいちくがくせいかくめい', ['四', '一九学生革命']), ('にいにいろくじけん', ['二', '二六事件']), ('ににはちじけん', ['二', '二八事件']), ('ぴーえむにてんご', ['5', 'PM2'])]:\n",
    "    yomi, ws = term\n",
    "    for w in ws:\n",
    "        del jpdc[(w, yomi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e8c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "yomikatas = {}\n",
    "for word, yomikata in jpdc:\n",
    "    if word not in words:\n",
    "        words[word] = [[jpdc[(word, yomikata)][0], yomikata]]\n",
    "    else:\n",
    "        words[word].append([jpdc[(word, yomikata)][0], yomikata])\n",
    "    if yomikata not in yomikatas:\n",
    "        yomikatas[yomikata] = [[jpdc[(word, yomikata)][0], word]]\n",
    "    else:\n",
    "        yomikatas[yomikata].append([jpdc[(word, yomikata)][0], word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f169c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix dangling entries\n",
    "for w in dangling:\n",
    "    if w in words:\n",
    "        if len(words[w]) == 1 or len(w) == 1:\n",
    "            for yw in words[w]:\n",
    "                keys = (w, yw[1])\n",
    "                jpdc[keys][0] += dangling[w][0]\n",
    "                yw[0] += dangling[w][0]\n",
    "                for t in yomikatas[keys[1]]:\n",
    "                    if t[1] == w:\n",
    "                        t[0] += dangling[w][0]\n",
    "                for books in dangling[w][1]:\n",
    "                    if books not in jpdc[keys][1]:\n",
    "                        jpdc[keys][1][books] = []\n",
    "                    for imis in dangling[w][1][books]:\n",
    "                        if imis not in jpdc[keys][1][books]:\n",
    "                            jpdc[keys][1][books].append(imis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98c355c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cache:\n",
    "    pre_jpdc = pickle.load(open('jpdc.pkl', 'rb'))\n",
    "\n",
    "for word, yomikata in jpdc:\n",
    "    if word in freqs:\n",
    "        ratio = 1\n",
    "        if use_cache:\n",
    "            total_weight = 0\n",
    "            self_weight = 0\n",
    "            for y in words[word]:\n",
    "                if (word, y[1]) in pre_jpdc:\n",
    "                    total_weight += pre_jpdc[(word, y[1])][0]\n",
    "                    if y[1] == yomikata:\n",
    "                        self_weight = pre_jpdc[(word, y[1])][0]\n",
    "            if total_weight != 0:\n",
    "                ratio = self_weight / total_weight\n",
    "        jpdc[(word, yomikata)][0] += freqs[word]*ratio\n",
    "    if (word, yomikata) in freqs:\n",
    "        jpdc[(word, yomikata)][0] += freqs[(word, yomikata)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e4e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    words[word] = sorted(words[word], key=lambda x: x[0], reverse=True)\n",
    "for yomikata in yomikatas:\n",
    "    yomikatas[yomikata] = sorted(\n",
    "        yomikatas[yomikata], key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdbfc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to merge same term\n",
    "for yomikata in yomikatas:\n",
    "    for i in range(len(yomikatas[yomikata])):\n",
    "        wordi = yomikatas[yomikata][i][1]\n",
    "        if all(map(lambda x: x in katakana or x in hiragana, wordi)) and len(yomikatas[yomikata]) > 2:\n",
    "            continue\n",
    "        imis = jpdc[(wordi, yomikata)][1]\n",
    "        for j in range(i+1, len(yomikatas[yomikata])):\n",
    "            wordj = yomikatas[yomikata][j][1]\n",
    "            if all(map(lambda x: x in katakana or x in hiragana, wordj)) and len(yomikatas[yomikata]) > 2:\n",
    "                continue\n",
    "            imisj = jpdc[(wordj, yomikata)][1]\n",
    "            flag = False\n",
    "            for k in set(imis.keys()).intersection(set(imisj.keys())):\n",
    "                flag = True\n",
    "                if imis[k] != imisj[k]:\n",
    "                    flag = False\n",
    "                    break\n",
    "            if flag:\n",
    "                for k in imisj:\n",
    "                    imis[k] = imisj[k]\n",
    "                jpdc[(wordj, yomikata)][1] = imis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "466ca26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual one-way merge some frequently used pairs\n",
    "oneway_pairs = [('する', '為る'), ('など', '等'), ('まで', '迄'), ('について', 'に就いて'), ('ではない', 'では無い'), ('ほど', '程'), ('てしまう', 'て仕舞う'), ('ながら', '乍ら'), ('そして', '然して'), ('によって', 'に因って'), ('による', 'に依る'), ('べし', '可し'), ('ことができる', '事ができる'), ('ことになる', '事になる'), ('つく', '付く'), ('ばかり', '許り'), ('にとって', 'に取って'), ('かもしれない', 'かも知れない'), ('どうして', '如何して'), ('といった', 'と言った'), ('ことがある',\n",
    "                                                                                                                                                                                                                                                                                                                                                            '事がある'), ('どうしても', '如何しても'), ('ことにする', '事にする'), ('ことはない', '事はない'), ('あんた', '貴方'), ('によると', 'に依ると'), ('こっち', '此方'), ('をもって', 'を以て'), ('とる', '取る'), ('によれば', 'に依れば'), ('さっき', '先'), ('とはいえ', 'とは言え'), ('といっても', 'と言っても'), ('にわたって', 'に渡って'), ('こととなる', '事となる'), ('あちこち', '彼方此方'), ('なる', '成る'), ('までもない', 'までも無い'), ('による', 'に依る'), ('にわたり', 'に渡り'), ('ここ', '此処')]\n",
    "for yomi in yomikatas:\n",
    "    if len(yomikatas[yomi]) == 2:\n",
    "        if yomikatas[yomi][0][1] == yomi:\n",
    "            if any(map(is_cjk, yomikatas[yomi][1][1])):\n",
    "                oneway_pairs.append((yomi, yomikatas[yomi][1][1]))\n",
    "        if yomikatas[yomi][1][1] == yomi:\n",
    "            if any(map(is_cjk, yomikatas[yomi][0][1])):\n",
    "                oneway_pairs.append((yomi, yomikatas[yomi][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcaa50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in oneway_pairs:\n",
    "    for k in jpdc[(pair[1], pair[0])][1]:\n",
    "        if k not in jpdc[(pair[0], pair[0])][1]:\n",
    "            jpdc[(pair[0], pair[0])][1][k] = []\n",
    "        for imi in jpdc[(pair[1], pair[0])][1][k]:\n",
    "            if imi not in jpdc[(pair[0], pair[0])][1][k]:\n",
    "                jpdc[(pair[0], pair[0])][1][k].append(imi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f14dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightlist = list(map(lambda x: x[0], jpdc.values()))\n",
    "weightlist.sort()\n",
    "for w in jpdc:\n",
    "    jpdc[w].append(len(weightlist)-bisect.bisect_right(weightlist, jpdc[w][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22ee2d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitches, Kanjium Pitch Accents\n",
      "Pitches, NHK\n",
      "Pitches, アクセント辞典\n",
      "Pitches, 三省堂国語辞典第八番\n",
      "Pitches, 新明解第八版\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir('jisho/'):\n",
    "    if 'Pitch Accent' in dir:\n",
    "        index = json.load(open('jisho/'+dir+'/index.json', 'r'))\n",
    "        for j in filter(lambda x: 'term_meta_bank' in x, os.listdir('jisho/'+dir)):\n",
    "            for term in json.load(open('jisho/'+dir+'/'+j, 'r')):\n",
    "                word, _, pitch = term\n",
    "                assert _ == 'pitch'\n",
    "                yomi = ''.join(\n",
    "                    map(lambda x: x['hira'], kks.convert(pitch['reading'])))\n",
    "                if (word, yomi) in jpdc:\n",
    "                    if len(jpdc[(word, yomi)]) == 3:\n",
    "                        jpdc[(word, yomi)].append(set())\n",
    "                    for p in pitch['pitches']:\n",
    "                        jpdc[(word, yomi)][3].add(p['position'])\n",
    "        print(f\"Pitches, {index['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c90af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(jpdc, open('jpdc.pkl', 'wb'))\n",
    "pickle.dump(yomikatas, open('yomikatas.pkl', 'wb'))\n",
    "pickle.dump(words, open('words.pkl', 'wb'))\n",
    "pickle.dump(freqs, open('freqs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24a43ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jpdc = pickle.load(open('jpdc.pkl', 'rb'))\n",
    "#yomikatas = pickle.load(open('yomikatas.pkl', 'rb'))\n",
    "#words = pickle.load(open('words.pkl', 'rb'))\n",
    "#freqs = pickle.load(open('freqs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7ddcde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = {}\n",
    "for w, yomi in jpdc:\n",
    "    for c in w:\n",
    "        if is_cjk(c):\n",
    "            if c not in cw:\n",
    "                cw[c] = 0\n",
    "            cw[c] += jpdc[(w, yomi)][0]\n",
    "\n",
    "# https://github.com/scriptin/kanji-frequency\n",
    "for j in os.listdir('jisho/kanji-frequency-master/data/'):\n",
    "    for term in json.load(open('jisho/kanji-frequency-master/data/'+j, 'r'))[1:]:\n",
    "        c = term[0]\n",
    "        if c not in cw:\n",
    "            cw[c] = 0\n",
    "        cw[c] += term[1]\n",
    "\n",
    "cwth = sorted(cw.items(), key=lambda x: x[1], reverse=True)[1500][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea2db961",
   "metadata": {},
   "outputs": [],
   "source": [
    "univar = []\n",
    "for l in list(filter(lambda x: len(x) > 4 and x[0] != '#', open('unihan/Unihan_Variants.txt').read().split('\\n'))):\n",
    "    l = l.split('\\t')\n",
    "    if l[1] == 'kSpecializedSemanticVariant':\n",
    "        continue\n",
    "    a = chr(int(l[0][2:], 16))\n",
    "    for b in l[2].split(' '):\n",
    "        b = chr(int(b.split('<')[0][2:], 16))\n",
    "        assert is_cjk(a) and is_cjk(b)\n",
    "        univar.append((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92d56fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shinjitai = \"亜（亞） 悪（惡） 圧（壓） 囲（圍） 医（醫） 為（爲） 壱（壹） 逸（逸） 隠（隱） 栄（榮） 営（營） 衛（衞） 駅（驛） 謁（謁） 円（圓） 塩（鹽） 縁（緣） 艶（艷） 応（應） 欧（歐） 殴（毆） 桜（櫻） 奥（奧） 横（橫） 温（溫） 穏（穩） 仮（假） 価（價） 禍（禍） 画（畫） 会（會） 悔（悔） 海（海） 絵（繪） 壊（壞） 懐（懷） 慨（慨） 概（槪） 拡（擴） 殻（殼） 覚（覺） 学（學） 岳（嶽） 楽（樂） 喝（喝） 渇（渴） 褐（褐） 缶（罐） 巻（卷） 陥（陷） 勧（勸） 寛（寬） 漢（漢） 関（關） 歓（歡） 観（觀） 気（氣） 祈（祈） 既（既） 帰（歸） 亀（龜） 器（器） 偽（僞） 戯（戲） 犠（犧） 旧（舊） 拠（據） 挙（擧） 虚（虛） 峡（峽） 挟（挾） 狭（狹） 郷（鄕） 響（響） 暁（曉） 勤（勤） 謹（謹） 区（區） 駆（驅） 勲（勳） 薫（薰） 径（徑） 茎（莖） 恵（惠） 掲（揭） 渓（溪） 経（經） 蛍（螢） 軽（輕） 継（繼） 鶏（鷄） 芸（藝） 撃（擊） 欠（缺） 研（硏） 県（縣） 倹（儉） 剣（劍） 険（險） 圏（圈） 検（檢） 献（獻） 権（權） 顕（顯） 験（驗） 厳（嚴） 広（廣） 効（效） 恒（恆） 黄（黃） 鉱（鑛） 号（號） 国（國） 黒（黑） 穀（穀） 砕（碎） 済（濟） 斎（齋） 剤（劑） 殺（殺） 雑（雜） 参（參） 桟（棧） 蚕（蠶） 惨（慘） 賛（贊） 残（殘） 糸（絲） 祉（祉） 視（視） 歯（齒） 児（兒） 辞（辭） 湿（濕） 実（實） 写（寫） 社（社） 者（者） 煮（煮） 釈（釋） 寿（壽） 収（收） 臭（臭） 従（從） 渋（澁） 獣（獸） 縦（縱） 祝（祝） 粛（肅） 処（處） 暑（暑） 署（署） 緒（緖） 諸（諸） 叙（敍） 将（將） 祥（祥） 称（稱） 渉（涉） 焼（燒） 証（證） 奨（奬） 条（條） 状（狀） 乗（乘） 浄（淨） 剰（剩） 畳（疊） 縄（繩） 壌（壤） 嬢（孃） 譲（讓） 醸（釀） 触（觸） 嘱（囑） 神（神） 真（眞） 寝（寢） 慎（愼） 尽（盡） 図（圖） 粋（粹） 酔（醉） 穂（穗） 随（隨） 髄（髓） 枢（樞） 数（數） 瀬（瀨） 声（聲） 斉（齊） 静（靜） 窃（竊） 摂（攝） 節（節） 専（專） 浅（淺） 戦（戰） 践（踐） 銭（錢） 潜（潛） 繊（纖） 禅（禪） 祖（祖） 双（雙） 壮（壯） 争（爭） 荘（莊） 捜（搜） 挿（插） 巣（巢） 曽（曾） 痩（瘦） 装（裝） 僧（僧） 層（層） 総（總） 騒（騷） 増（增） 憎（憎） 蔵（藏） 贈（贈） 臓（臟） 即（卽） 属（屬） 続（續） 堕（墮） 対（對） 体（體） 帯（帶） 滞（滯） 台（臺） 滝（瀧） 択（擇） 沢（澤） 担（擔） 単（單） 胆（膽） 嘆（嘆） 団（團） 断（斷） 弾（彈） 遅（遲） 痴（癡） 虫（蟲） 昼（晝） 鋳（鑄） 著（著） 庁（廳） 徴（徵） 聴（聽） 懲（懲） 勅（敕） 鎮（鎭） 塚（塚） 逓（遞） 鉄（鐵） 点（點） 転（轉） 伝（傳） 都（都） 灯（燈） 当（當） 党（黨） 盗（盜） 稲（稻） 闘（鬭） 徳（德） 独（獨） 読（讀） 突（突） 届（屆） 難（難） 弐（貳） 悩（惱） 脳（腦） 覇（霸） 拝（拜） 廃（廢） 売（賣） 梅（梅） 麦（麥） 発（發） 髪（髮） 抜（拔） 繁（繁） 晩（晚） 蛮（蠻） 卑（卑） 秘（祕） 碑（碑） 浜（濱） 賓（賓） 頻（頻） 敏（敏） 瓶（甁） 侮（侮） 福（福） 払（拂） 仏（佛） 併（倂） 並（竝） 塀（塀） 餅（餠） 辺（邊） 変（變） 弁（辨） 弁（瓣） 弁（辯） 勉（勉） 歩（步） 宝（寶） 豊（豐） 褒（襃） 墨（墨） 翻（飜） 毎（每） 万（萬） 満（滿） 免（免） 麺（麵） 黙（默） 弥（彌） 訳（譯） 薬（藥） 与（與） 予（豫） 余（餘） 誉（譽） 揺（搖） 様（樣） 謡（謠） 来（來） 頼（賴） 乱（亂） 覧（覽） 欄（欄） 竜（龍） 隆（隆） 虜（虜） 両（兩） 猟（獵） 緑（綠） 涙（淚） 塁（壘） 類（類） 礼（禮） 励（勵） 戻（戾） 霊（靈） 齢（齡） 暦（曆） 歴（歷） 恋（戀） 練（練） 錬（鍊） 炉（爐） 労（勞） 郎（郞） 朗（朗） 廊（廊） 楼（樓） 録（錄） 湾（灣） 亘（亙） 凜（凛） 尭（堯） 巌（巖） 晃（晄） 桧（檜） 槙（槇） 渚（渚） 猪（豬） 琢（琢） 祢（禰） 祐（祐） 祷（禱） 禄（祿） 禎（禎） 穣（穰） 萌（萠） 遥（遙） 唖（啞） 頴（穎） 鴎（鷗） 撹（攪） 麹（麴） 鹸（鹼） 噛（嚙） 繍（繡） 蒋（蔣） 醤（醬） 曽（曾） 掻（搔） 痩（瘦） 祷（禱） 屏（屛） 并（幷） 桝（枡） 麺（麵） 沪（濾） 芦（蘆） 蝋（蠟） 弯（彎）\"\n",
    "for l in shinjitai.split(' '):\n",
    "    a = l[0]\n",
    "    b = l[2]\n",
    "    assert is_cjk(a) and is_cjk(b)\n",
    "    assert a != b\n",
    "    univar.append((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b53bb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in os.listdir('sts-data'):\n",
    "    with open('sts-data/'+txt, 'r') as f:\n",
    "        for l in f.read().split('\\n'):\n",
    "            l = l.split('\\t')\n",
    "            if len(l) > 1:\n",
    "                a = l[0]\n",
    "                for b in l[1].split(' '):\n",
    "                    univar.append((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec883fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisjointSet(object):\n",
    "\n",
    "    def __init__(self, weight):\n",
    "        self.leader = {}  # maps a member to the group's leader\n",
    "        self.group = {}  # maps a group leader to the group (which is a set)\n",
    "        self.weight = weight\n",
    "\n",
    "    def comp(self, leadera, leaderb, groupa, groupb):\n",
    "        if leadera in self.weight:\n",
    "            if leaderb in self.weight:\n",
    "                return self.weight[leadera] < self.weight[leaderb]\n",
    "            else:\n",
    "                return False\n",
    "        elif leaderb in self.weight:\n",
    "            return True\n",
    "        else:\n",
    "            return len(groupa) < len(groupb)\n",
    "\n",
    "    def add(self, a, b):\n",
    "        if a not in self.leader:\n",
    "            self.leader[a] = a\n",
    "            self.group[a] = set([a])\n",
    "        if b not in self.leader:\n",
    "            self.leader[b] = b\n",
    "            self.group[b] = set([b])\n",
    "        leadera = self.leader.get(a)\n",
    "        leaderb = self.leader.get(b)\n",
    "        if leadera == leaderb:\n",
    "            return  # nothing to do\n",
    "        groupa = self.group[leadera]\n",
    "        groupb = self.group[leaderb]\n",
    "        if self.comp(leadera, leaderb, groupa, groupb):\n",
    "            a, leadera, groupa, b, leaderb, groupb = b, leaderb, groupb, a, leadera, groupa\n",
    "        groupa |= groupb\n",
    "        del self.group[leaderb]\n",
    "        for k in groupb:\n",
    "            self.leader[k] = leadera\n",
    "\n",
    "\n",
    "ds = DisjointSet(cw)\n",
    "for a, b in univar:\n",
    "    # Remove unreasonable variants\n",
    "    if not set((a, b)).intersection(set(['子', '予', '完', '着', '版', '合'])):\n",
    "        ds.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd1c93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ds.group.copy():\n",
    "    if x not in cw:\n",
    "        del ds.group[x]\n",
    "for x in ds.leader.copy():\n",
    "    if ds.leader[x] not in cw:\n",
    "        del ds.leader[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b287a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cjconvert = {}\n",
    "for x in ds.leader:\n",
    "    if (x not in cw or cw[x] < cwth) and x != ds.leader[x]:\n",
    "        cjconvert[x] = ds.leader[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "141c3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "convertjs = json.dumps(cjconvert, ensure_ascii=False,\n",
    "                       indent=\"\", sort_keys=True)\n",
    "with open('../lib/cjconvert.dart', 'w') as f:\n",
    "    f.write(f\"Map<String,String> cjdc = {convertjs};\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e38a1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = 0\n",
    "for w in words:\n",
    "    if any(map(lambda x: x in cjconvert, w)):\n",
    "        if ml < len(w):\n",
    "            ml = len(w)\n",
    "assert max(map(len, words.keys())) < 100 and max(\n",
    "    map(len, yomikatas.keys())) < 60 and ml < 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9e7f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"../db/arujisho.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36a37ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fcc27efce40>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('''CREATE VIRTUAL TABLE IF NOT EXISTS jpdc USING fts4(word NVARCHAR(100) NOT NULL, yomikata NVARCHAR(60) NOT NULL, romaji VARCHAR(108) NOT NULL,\n",
    "            freqRank INTEGER NOT NULL NOT INDEXED,\n",
    "            rword NVARCHAR(100) NOT NULL, ryomikata NVARCHAR(60) NOT NULL, rromaji VARCHAR(108) NOT NULL,\n",
    "            pitchData VARCHAR(20) NOT INDEXED,\n",
    "            origForm NVARCHAR(40) NOT INDEXED,\n",
    "            idex INTEGER NOT NULL)''')\n",
    "cur.execute(\n",
    "    '''CREATE TABLE IF NOT EXISTS imis (imi TEXT NOT NULL, orig TEXT NOT NULL)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d223b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = {}\n",
    "c = 1\n",
    "for w, v in sorted(jpdc.items(), key=lambda x: x[1][2]):\n",
    "    jData = json.dumps(v[1], ensure_ascii=False, sort_keys=True)\n",
    "    if jData not in dups:\n",
    "        cur.execute('INSERT INTO imis VALUES (?, ?)', (jData, w[0]))\n",
    "        dups[jData] = (c, w[0])\n",
    "        c += 1\n",
    "    romaji = ''.join(\n",
    "        map(lambda x: x['hepburn'], kks.convert(w[1]))).replace(\"'\", '')\n",
    "    word = ''.join(\n",
    "        map(lambda x: x if x not in cjconvert else cjconvert[x], w[0]))\n",
    "    cur.execute('INSERT INTO jpdc VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',\n",
    "                (word, w[1], romaji, v[2],\n",
    "                 word[::-1], w[1][::-1], romaji[::-1],\n",
    "                 str(sorted(list(v[3]))) if len(v) > 3 else '', '' if word == w[0] else w[0], dups[jData][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f73d2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit()\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
